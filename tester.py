import os
import ember
import tensorflow as tf
import numpy as np
from sklearn.preprocessing import StandardScaler
import pickle

def check_path_type(path):
    if os.path.isfile(path):
        return "file"
    elif os.path.isdir(path):
        return "dir"
    else:
        return None
    

def tester(file, model, scaler):
    # Reads binary of the uploaded file
    file_data = open(file, "rb").read()
    # Initalises the feature extractor
    feature_extractor = ember.PEFeatureExtractor(2)

    # Extracts features from the binary content
    file_data = np.array(feature_extractor.feature_vector(file_data), dtype=np.float32)
    # Scales the features based on the trained scaler
    file_data = scaler.transform([file_data])
    # Reshapes the feature array to match the expectd input array feature size
    file_data = np.reshape(file_data,(-1,1,2381))

    # Creates a prediction based on the processed feature array
    prediction = model.predict(file_data)

    return prediction



def main(path):
    # Loads scaler file
    with open('scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    
    # Loads TensorFlow model file
    model = tf.keras.models.load_model('model.h5')

    # Checks if the upload is a file or directory
    type = check_path_type(path)
    if type == "file":
        result = (tester(path, model, scaler))
        if result > 0.5:
            return "malicious"
        else:
            string = "benign"
            return string
    elif type == "dir":
        file_paths = []

        for root, directoy, files in os.walk(path):
            for file in files:
                file_paths.append(os.path.join(root, file))

        results = []
        for file in file_paths:
            results.append(tester(file, model, scaler))
        
        print(results)

